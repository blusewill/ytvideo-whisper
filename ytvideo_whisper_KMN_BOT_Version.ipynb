{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blusewill/ytvideo-whisper/blob/dev/ytvideo_whisper_KMN_BOT_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQL1GjFTNNp"
      },
      "source": [
        "# ytvideo-whisper 機器狼特別版\n",
        "\n",
        "這個專案採用了[Whisper](https://github.com/openai/whisper)而不是以前在用的Decipher專案\n",
        "\n",
        "如果想要用原本的Whisper專案，就在這裡"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZvIN-oUKdx"
      },
      "source": [
        "# 使用方法\n",
        "\n",
        "1. 請確認你的執行階段有啟用GPU，在 ``執行階段 -> 變更執行階段類型 ``\n",
        "1. 更改設定\n",
        "1. 按下 ``執行階段 -> 執行全部`` 或是 (CTRL+F9)\n",
        "1. 然後連接到Google雲端硬碟\n",
        "1. 然後等一下你的檔案應該就會在 ``雲端硬碟 -> Whisper -> result``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpjyRvaUVZh"
      },
      "source": [
        "## 獲得Google雲端硬碟權限\n",
        "(在 雲端硬碟 -> Whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M2C9UlxTCjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16057d72-6092-4cb9-bea4-2e28f6142c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **下載選項**\n",
        "#@markdown ---\n",
        "#@markdown ## **停用Google雲端硬碟**\n",
        "disable_google_drive = \"no\" #@param ['yes', 'no']\n",
        "#@markdown ## **下載方式** ``anonfile / 直線下載``\n",
        "download_method = \"anonfile\" #@param ['anonfile', 'direct']\n",
        "#@markdown 當啟用 ``結束自動刪除執行階段`` 的時候**無法**使用直線下載，會回到上傳到anonfiles的方式。請見諒 </p>\n",
        "#@markdown **警告：直線下載有時候無法在Firefox或類Firefox瀏覽器 (WaterFox , Librewolf)使用**。如果無法使用的話，請**切換到上傳檔案到anonfile**。\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  path = '/content/gdrive/MyDrive/Whisper/'\n",
        "  path2 = '/content/gdrive/MyDrive/Whisper/result'\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiME-JOSUfhd"
      },
      "source": [
        "# 安裝程式\n",
        "yt-dlp ffmpeg openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXCqLjY0Uz0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c957c7-c352-43bb-a71a-305d1d740b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.3.4-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Collecting tiktoken==0.3.1 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.5)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2022.12.7)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, ffmpeg\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796910 sha256=d282bdc5a0896ba5fac4f766e58087a736b8081881320a2310bdd06f2899da32\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/13/5f/fe8245f6dc59df505879da4b2129932e342f02a80e6b87f27d\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=428ee5c5365d62ec521e615a54cc457512d4e08a9076db08755e9df37ba2e41b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built openai-whisper ffmpeg\n",
            "Installing collected packages: ffmpeg, brotli, websockets, pycryptodomex, mutagen, ffmpeg-python, yt-dlp, tiktoken, openai-whisper\n",
            "Successfully installed brotli-1.0.9 ffmpeg-1.4 ffmpeg-python-0.2.0 mutagen-1.46.0 openai-whisper-20230314 pycryptodomex-3.18.0 tiktoken-0.3.1 websockets-11.0.3 yt-dlp-2023.3.4\n"
          ]
        }
      ],
      "source": [
        "! pip install openai-whisper yt-dlp ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfd0B3nU_5o"
      },
      "source": [
        "# 測試GPU是否有開啟\n",
        "\n",
        "如果沒有東西跑出來的話，請去 ``執行階段 -> 變更執行階段類型`` 更改"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukF_tYc9VfGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75749c8-9cc9-4e8f-bc64-169874159edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 30 15:11:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpdHsXmVqsv"
      },
      "source": [
        "# 設定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IccTHdDOVxgL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#@markdown # **設定**\n",
        "#@markdown ---\n",
        "#@markdown ## **影片連接**\n",
        "# YouTube Link\n",
        "YouTube_Video_Link = \"https://www.youtube.com/watch?v=xWOI2c1LFQc\" #@param {type:\"string\"}\n",
        "# File Name Change\n",
        "#@markdown ## **檔案名稱**\n",
        "new_filename = \"test\" #@param {type:\"string\"}\n",
        "#@markdown ## **語言**\n",
        "language = \"Auto\" #@param [\"Auto\", \"Chinese\", \"English\", \"Japanese\"]\n",
        "#@markdown ## **模式 ``生成 / 翻譯``**\n",
        "task = \"transcribe\" #@param ['transcribe', 'translate']\n",
        "# Change it to srt file type\n",
        "new_filename = os.path.splitext(new_filename)[0] + \".srt\"\n",
        "new_filename2 = os.path.splitext(new_filename)[0] + \" Transcript.txt\"\n",
        "# Change the Model of the Whisper\n",
        "#@markdown # **其他選項**\n",
        "#@markdown ---\n",
        "#@markdown ## **生產逐字稿**\n",
        "Generate_Plain_Document = \"yes\" #@param ['yes','no']\n",
        "#@markdown ## **結束自動刪除執行階段**\n",
        "shutdown_after_complete = \"yes\" #@param ['yes','no']\n",
        "#@markdown ## **模型**\n",
        "model_user = \"medium\" #@param ['tiny.en','tiny','base.en','base','small.en','small','medium.en','medium','large-v1','large-v2','large']\n",
        "#@markdown ## **Cookies驗證**\n",
        "enable_cookies = \"no\" #@param ['yes', 'no']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 如果你有啟動Cookies驗證\n",
        "請在這裡上傳Cookies檔案"
      ],
      "metadata": {
        "id": "MQa-cRGkAopn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "  print(\"It is not recommended to upload your main account's cookies files here, as this is a shared environment.\")\n",
        "  print(\"Your cookies might get leaked, and I will not take any responsibility if your account gets stolen.\")\n",
        "  print(\"The recommended approach is to use another Google Account's cookies to run this tool.\")\n",
        "  print(\"If it is a private video, you can share the video with that Google Account to grant access to it.\")\n",
        "  print(\"\")\n",
        "\n",
        "  from google.colab import files\n",
        "  cookies = files.upload()\n",
        "\n",
        "  # Specify the path where the files are located\n",
        "  path_cookies = \"/content\"\n",
        "\n",
        "  def rename_files(path_cookies):\n",
        "      for filename in os.listdir(path_cookies):\n",
        "          file_path = os.path.join(path_cookies, filename)\n",
        "          if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
        "              new_path = os.path.join(path_cookies, \"cookies.txt\")\n",
        "              os.rename(file_path, new_path)\n",
        "\n",
        "  rename_files(path_cookies)"
      ],
      "metadata": {
        "id": "hPMZ1BQLAoY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vEu7rbV6xJ"
      },
      "source": [
        "# 下載影片\n",
        "使用yt-dlp跟ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6o0YbciV_aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b937ad-9550-46ae-b092-a92685bf4c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=xWOI2c1LFQc\n",
            "[youtube] xWOI2c1LFQc: Downloading webpage\n",
            "[youtube] xWOI2c1LFQc: Downloading android player API JSON\n",
            "[youtube] xWOI2c1LFQc: Downloading player bbe1b497\n",
            "[info] xWOI2c1LFQc: Downloading 1 format(s): 251\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: content/audio\n",
            "[download] 100% of    4.27MiB in 00:00:00 at 29.72MiB/s              \n",
            "[ExtractAudio] Destination: content/audio.mp3\n",
            "Deleting original file content/audio (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "import yt_dlp\n",
        "\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "\n",
        "  ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "          'cookiefile': 'cookies.txt'\n",
        "  }\n",
        "\n",
        "else:\n",
        "\n",
        "    ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "  }\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([YouTube_Video_Link])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzO86nhoWPu2"
      },
      "source": [
        "# 生成字幕檔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnFM1sy3WTBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1dbb330-4285-43a4-b89d-7b4a11babd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Chinese\n",
            "[00:00.000 --> 00:05.000] - 字幕由 Amara.org 社群提供-\n",
            "[00:10.880 --> 00:15.080] 那 StableDiffusion 我們現在畫一張它的架構圖\n",
            "[00:15.080 --> 00:16.680] 這樣大家比較好\n",
            "[00:16.680 --> 00:20.280] 就要有個好想像的根據\n",
            "[00:20.280 --> 00:22.240] 好 我們就一步一步來把\n",
            "[00:22.240 --> 00:25.000] StableDiffusion 的架構圖給畫出來\n",
            "[00:25.000 --> 00:30.680] 因為它是一個自由免費開放的繪圖AI\n",
            "[00:30.680 --> 00:34.240] 而且它程式碼跟模型也都給大家了\n",
            "[00:34.240 --> 00:38.760] 所以它其實更像是一個工具的基底的感覺\n",
            "[00:38.760 --> 00:40.840] 或者是用比較專業的講法\n",
            "[00:40.840 --> 00:43.200] 就是它是一個框架\n",
            "[00:43.200 --> 00:47.480] 我們這個系列會介紹到許許多多不同的功能\n",
            "[00:47.480 --> 00:53.040] 其實它們都是世界上某個別人開發的\n",
            "[00:54.000 --> 00:56.000] 這個叫 Model\n",
            "[00:56.000 --> 00:57.400] 就是模型\n",
            "[00:57.400 --> 01:01.440] 就是對應到剛剛那個AI的資料集的部分\n",
            "[01:01.440 --> 01:05.400] 就是 StableDiffusion 它原本它們就有\n",
            "[01:05.400 --> 01:09.120] 用網路上的資料去訓練了它們的\n",
            "[01:09.120 --> 01:11.840] 那個 StableDiffusion 的模型\n",
            "[01:11.840 --> 01:14.000] 它的特點就大概是一些\n",
            "[01:14.000 --> 01:19.640] 它可以畫出一些比較偏寫實的圖片這樣子\n",
            "[01:19.640 --> 01:23.920] 可是如果這個繪圖AI只能畫\n",
            "[01:23.920 --> 01:27.560] 就是偏有點寫實但又不會太寫實的圖\n",
            "[01:27.560 --> 01:30.000] 那基本上它一定不會這麼紅\n",
            "[01:30.000 --> 01:32.080] 所以這邊就要來講\n",
            "[01:32.080 --> 01:34.240] 包括像 NovoAI 在內\n",
            "[01:34.240 --> 01:35.720] 就有很多人去畫了\n",
            "[01:35.720 --> 01:39.160] 就有很多人去練了動漫的圖\n",
            "[01:39.160 --> 01:40.120] Anime 的圖\n",
            "[01:40.120 --> 01:41.280] 那它就可以\n",
            "[01:41.280 --> 01:46.960] 這個模型它就可以產出二次元美少女的圖這樣\n",
            "[01:47.000 --> 01:50.680] 然後如果你想要獸人的話\n",
            "[01:50.680 --> 01:55.520] 也有人有練 Kemono 或是歐美那種寫實Furi\n",
            "[01:55.520 --> 01:57.720] 它就會產出不同的圖\n",
            "[01:57.720 --> 02:00.120] 然後或者是最近還有一個很紅的\n",
            "[02:00.120 --> 02:01.800] 就是 AI Courser 這樣\n",
            "[02:01.800 --> 02:03.760] 就是比較偏真人\n",
            "[02:03.760 --> 02:05.400] 它看起來會像照片\n",
            "[02:05.400 --> 02:06.680] 然後會有那個\n",
            "[02:06.680 --> 02:09.200] 它產出的圖就像是真人\n",
            "[02:09.200 --> 02:11.600] 真人美少女的那種照片\n",
            "[02:11.600 --> 02:12.960] 叫 AI Courser\n",
            "[02:14.240 --> 02:15.960] 好這個叫模型\n",
            "[02:15.960 --> 02:18.240] 就是用不同的圖\n",
            "[02:18.240 --> 02:20.960] And 文字去訓練出來的\n",
            "[02:20.960 --> 02:23.800] 但它們通通底下都是用\n",
            "[02:23.800 --> 02:25.760] Stable Diffusion\n",
            "[02:25.760 --> 02:28.160] 去當它們的基底工具\n",
            "[02:29.720 --> 02:32.640] 然後它另外還有一個就是\n",
            "[02:32.640 --> 02:35.280] 我機箱會把它畫在旁邊了\n",
            "[02:37.640 --> 02:39.160] 就是這邊畫了四個圓\n",
            "[02:39.160 --> 02:42.200] 然後從它的基底長出來\n",
            "[02:42.200 --> 02:45.680] 大家可以想像成這個機器人\n",
            "[02:45.680 --> 02:48.400] 就是有些人覺得這個機器人不夠厲害\n",
            "[02:48.400 --> 02:51.600] 就是原本的那個小腦袋家\n",
            "[02:51.600 --> 02:53.000] 他的訓練級還不夠\n",
            "[02:53.000 --> 02:54.800] 就是全世界的工程師們\n",
            "[02:54.800 --> 02:57.480] 想要把它組裝成超級超強機器人\n",
            "[02:57.480 --> 02:59.920] 所以在他的腦袋上面插針\n",
            "[02:59.920 --> 03:01.320] 但是這種感覺\n",
            "[03:01.320 --> 03:04.280] 這個就是它的擴充功能\n",
            "[03:04.280 --> 03:06.160] 全世界工程師們很厲害\n",
            "[03:06.160 --> 03:07.440] 就是它們可以去\n",
            "[03:07.440 --> 03:08.640] 各式各樣的論文\n",
            "[03:08.640 --> 03:10.880] 然後去找出各式各樣的AI技術\n",
            "[03:10.880 --> 03:13.040] 然後來改善這整個\n",
            "[03:13.080 --> 03:17.840] 這整個Stable Diffusion的功能\n",
            "[03:17.840 --> 03:19.440] 然後可是相對的\n",
            "[03:19.440 --> 03:21.520] 這整個東西就會變得非常的複雜\n",
            "[03:21.520 --> 03:23.640] 就是有很多東西你就是不知道\n",
            "[03:23.640 --> 03:26.200] 而且這個全世界工程師就是每天\n",
            "[03:26.200 --> 03:27.440] 搞不好每個禮拜\n",
            "[03:27.440 --> 03:30.680] 他差不多每個禮拜就會出一個新東西這樣\n",
            "[03:30.680 --> 03:35.840] 然後就是如果沒有\n",
            "[03:35.840 --> 03:38.400] 如果大家沒有互相分享情報的話\n",
            "[03:38.400 --> 03:41.120] 其實你很難知道\n",
            "[03:41.120 --> 03:42.240] 有一個好用的東西\n",
            "[03:42.240 --> 03:46.280] 就在世界的某個角落冒出來這樣\n",
            "[03:46.280 --> 03:49.920] 這個是機器人目前玩到現在的一點小心得\n",
            "[03:49.920 --> 03:51.480] 這些都是跟他的架構\n",
            "[03:51.480 --> 03:53.080] 還有他的背景故事有關\n",
            "[03:53.080 --> 03:56.600] 所以一開始你在找那個模型檔的時候\n",
            "[03:56.600 --> 03:59.720] 你就要特別找過\n",
            "[03:59.720 --> 04:03.760] 不然你再怎麼唱都唱不出來\n",
            "[04:03.760 --> 04:05.520] 然後擴充功能的話\n",
            "[04:05.520 --> 04:07.320] 這個機器人現在還在學\n",
            "[04:07.320 --> 04:09.960] 因為他東西實在太多\n",
            "[04:09.960 --> 04:10.720] 簡單講之下\n",
            "[04:10.760 --> 04:12.280] 至少是有人帶你入門\n",
            "[04:12.280 --> 04:17.720] 好那我們差不多可以來到今天的\n",
            "[04:17.720 --> 04:20.720] Thanks for watching\n",
            "[04:20.720 --> 04:23.880] 今天的ED卡就是跟縮圖那張是同一張\n",
            "[04:23.880 --> 04:26.960] 但是畫面變得比較乾淨一點\n",
            "Generated srt and txt file in the Google Drive -> Whisper -> result Folder\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(model_user)\n",
        "\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "filename = \"audio.mp3\"\n",
        "input_directory = \"content\"\n",
        "input_file = f\"{input_directory}/{filename}\"\n",
        "if language.lower() == 'auto':\n",
        "  result = model.transcribe(input_file, verbose=True, task=task)\n",
        "else:\n",
        "  result = model.transcribe(input_file, verbose=True, task=task, language=language)\n",
        "\n",
        "if enable_direct_download.lower() == 'no':\n",
        "\n",
        "  transcription_root = \"/content/gdrive/MyDrive/Whisper/result\"\n",
        "\n",
        "else:\n",
        "  os.mkdir(\"result\")\n",
        "  transcription_root = \"/content/result\"\n",
        "\n",
        "# Save as an SRT file\n",
        "srt_writer = get_writer(\"srt\", transcription_root,)\n",
        "srt_writer(result, new_filename)\n",
        "\n",
        "if Generate_Plain_Document.lower() == \"yes\":\n",
        "\n",
        "  # Save as TXT file\n",
        "  srt_writer = get_writer(\"txt\", transcription_root,)\n",
        "  srt_writer(result, new_filename2)\n",
        "  print(\"Generated srt and txt file in the Google Drive -> Whisper -> result Folder\")\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Generated srt file in the Google Drive -> Whisper -> result Folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 壓縮檔案並上傳\n",
        "如果雲端硬碟被停用了"
      ],
      "metadata": {
        "id": "7rWCkivc2Jhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os.path\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "if disable_google_drive.lower() == 'yes':\n",
        "    # Creating the ZIP file\n",
        "    archived = shutil.make_archive(new_filename, 'zip', '/content/result')\n",
        "\n",
        "    if os.path.exists(archived):\n",
        "        print(archived)\n",
        "\n",
        "        if shutdown_after_complete.lower() == \"yes\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        elif download_method.lower() == \"anonfile\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        else:\n",
        "            files.download(archived)\n",
        "            print(\"File downloaded successfully.\")\n",
        "\n",
        "    else:\n",
        "        print(\"ZIP file not created\")"
      ],
      "metadata": {
        "id": "H-PkcMx22JTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM61x2JuYBl-"
      },
      "source": [
        "# 自動關閉執行階段"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUKHF0-rYGvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "824c6b0b-65e3-4864-bf9a-224b2986f11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting Down the Runtime Because Shutdown After Complete is on\n"
          ]
        }
      ],
      "source": [
        "if shutdown_after_complete.lower() == \"yes\":\n",
        "    print(\"Shutting Down the Runtime Because Shutdown After Complete is on\")\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HiME-JOSUfhd"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMR5zOuLi2KeOk6niLMPeEl",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}