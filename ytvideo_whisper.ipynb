{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blusewill/ytvideo-whisper/blob/master/ytvideo_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQL1GjFTNNp"
      },
      "source": [
        "# ytvideo-whisper\n",
        "\n",
        "This Project uses the Original [Whisper](https://github.com/openai/whisper) Project instead of Decipher Project.\n",
        "\n",
        "For Everyone who want to use the Original Whisper Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZvIN-oUKdx"
      },
      "source": [
        "# Usage\n",
        "\n",
        "1. Check the Runtime Type is on GPU Mode in ``Runtime -> Change Runtime Type ``\n",
        "1. Change the Settings at Settings Code Block\n",
        "1. Click ``Runtime -> Run all`` (CTRL+F9)\n",
        "1. Click on the Connect to Google Drive\n",
        "1. And Wait for a moment your Generated Srt should be on ``Google Drive -> Whisper -> result``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpjyRvaUVZh"
      },
      "source": [
        "## Add Google Drive Access\n",
        "(at Google Drive/Whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M2C9UlxTCjE"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Download Opition**\n",
        "disable_google_drive = \"no\" #@param ['yes', 'no']\n",
        "download_method = \"transfer.sh\" #@param ['anonfile', 'transfer.sh', 'direct']\n",
        "#@markdown The Driect Method will **NOT** Working if the ``shutdown_after_complete`` is enabled. It will **Fall Back to anonfile or transfer.sh** instead.\n",
        "#@markdown # Disclaimer : The Direct Download sometimes doesn't work on Firefox Type Web Browser. </p> Please **use anonfile or transfer.sh instead**\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  path = '/content/gdrive/MyDrive/Whisper/'\n",
        "  path2 = '/content/gdrive/MyDrive/Whisper/result'\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiME-JOSUfhd"
      },
      "source": [
        "# Install Components\n",
        "\n",
        "Package : openai-whisper yt-dlp ipython transfersh_client pyperclip wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXCqLjY0Uz0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fde7b31-a88f-453e-f9c6-5b77a6069901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.7.6-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting transfersh_client\n",
            "  Downloading transfersh_client-1.1.3-py2.py3-none-any.whl (6.3 kB)\n",
            "Collecting pyperclip\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Collecting tiktoken==0.3.1 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.6)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m894.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, pyperclip, wget\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796908 sha256=5629172fc42d231a523921da5f75750f1f8320750b51af2622a3cad6f9994801\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/13/5f/fe8245f6dc59df505879da4b2129932e342f02a80e6b87f27d\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11123 sha256=5b67490a1c66d31498c70138b10490b816dce951459d9e212178f6522b03bff4\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/24/fe/140a94a7f1036003ede94579e6b4227fe96c840c6f4dcbe307\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=b01c6dec142b2e75a3c60d7c2ffa42e354513a44fe8adaa290180dba558bd952\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built openai-whisper pyperclip wget\n",
            "Installing collected packages: wget, transfersh_client, pyperclip, brotli, websockets, pycryptodomex, mutagen, jedi, ffmpeg-python, yt-dlp, tiktoken, openai-whisper\n",
            "Successfully installed brotli-1.0.9 ffmpeg-python-0.2.0 jedi-0.19.0 mutagen-1.46.0 openai-whisper-20230314 pycryptodomex-3.18.0 pyperclip-1.8.2 tiktoken-0.3.1 transfersh_client-1.1.3 websockets-11.0.3 wget-3.2 yt-dlp-2023.7.6\n"
          ]
        }
      ],
      "source": [
        "! apt-get install ffmpeg\n",
        "! pip install openai-whisper yt-dlp ipython transfersh_client pyperclip wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfd0B3nU_5o"
      },
      "source": [
        "# GPU Checkup\n",
        "\n",
        "If Nothing shows up means you didn't enable GPU in the ``Runtime -> Change Runtime type``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukF_tYc9VfGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92f521a-5c0c-4b45-aee2-8484648e28a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Aug  2 17:24:55 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpdHsXmVqsv"
      },
      "source": [
        "# Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IccTHdDOVxgL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#@markdown # **Video Link Here**\n",
        "# YouTube Link\n",
        "YouTube_Video_Link = \"https://www.youtube.com/watch?v=ZR_Kjg9GIBM\" #@param {type:\"string\"}\n",
        "# File Name Change\n",
        "new_filename = \"How I Take Notes in 2023\" #@param {type:\"string\"}\n",
        "#@markdown Note: Leave it Blank to let it audio Detect the Language\n",
        "language = \"\" #@param {type:\"string\"}\n",
        "task = \"transcribe\" #@param ['transcribe', 'translate']\n",
        "# Change it to srt file type\n",
        "new_filename = os.path.splitext(new_filename)[0] + \".srt\"\n",
        "new_filename2 = os.path.splitext(new_filename)[0] + \" Transcript.txt\"\n",
        "# Change the Model of the Whisper\n",
        "#@markdown # **Other Options**\n",
        "Generate_Plain_Document = \"yes\" #@param ['yes','no']\n",
        "shutdown_after_complete = \"yes\" #@param ['yes','no']\n",
        "model_user = \"medium\" #@param ['tiny.en','tiny','base.en','base','small.en','small','medium.en','medium','large-v1','large-v2','large']\n",
        "enable_cookies = \"no\" #@param ['yes', 'no']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Enable Cookies is Enabled\n",
        "Upload your Cookies file in here"
      ],
      "metadata": {
        "id": "MQa-cRGkAopn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "  print(\"It is not recommended to upload your main account's cookies files here, as this is a shared environment.\")\n",
        "  print(\"Your cookies might get leaked, and I will not take any responsibility if your account gets stolen.\")\n",
        "  print(\"The recommended approach is to use another Google Account's cookies to run this tool.\")\n",
        "  print(\"If it is a private video, you can share the video with that Google Account to grant access to it.\")\n",
        "  print(\"\")\n",
        "\n",
        "  from google.colab import files\n",
        "  cookies = files.upload()\n",
        "\n",
        "  # Specify the path where the files are located\n",
        "  path_cookies = \"/content\"\n",
        "\n",
        "  def rename_files(path_cookies):\n",
        "      for filename in os.listdir(path_cookies):\n",
        "          file_path = os.path.join(path_cookies, filename)\n",
        "          if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
        "              new_path = os.path.join(path_cookies, \"cookies.txt\")\n",
        "              os.rename(file_path, new_path)\n",
        "\n",
        "  rename_files(path_cookies)"
      ],
      "metadata": {
        "id": "hPMZ1BQLAoY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vEu7rbV6xJ"
      },
      "source": [
        "# Download the Video\n",
        "using the yt-dlp and ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6o0YbciV_aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbe5ace-bdfd-4ab2-c30a-61df52dfd5de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ZR_Kjg9GIBM\n",
            "[youtube] ZR_Kjg9GIBM: Downloading webpage\n",
            "[youtube] ZR_Kjg9GIBM: Downloading ios player API JSON\n",
            "[youtube] ZR_Kjg9GIBM: Downloading android player API JSON\n",
            "[youtube] ZR_Kjg9GIBM: Downloading m3u8 information\n",
            "[info] ZR_Kjg9GIBM: Downloading 1 format(s): 251\n",
            "[download] Destination: content/audio\n",
            "[download] 100% of    4.07MiB in 00:00:00 at 54.92MiB/s  \n",
            "[ExtractAudio] Destination: content/audio.mp3\n",
            "Deleting original file content/audio (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "import yt_dlp\n",
        "\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "\n",
        "  ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "          'cookiefile': 'cookies.txt'\n",
        "  }\n",
        "\n",
        "else:\n",
        "\n",
        "    ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "  }\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([YouTube_Video_Link])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzO86nhoWPu2"
      },
      "source": [
        "# Generating the SRT file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnFM1sy3WTBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9300cf78-487d-42e5-f5c3-051d643c892c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:13<00:00, 34.8MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:10.320]  What do I use for note taking? Neovim? For the most part? I am so basic on this. Oh man.\n",
            "[00:10.320 --> 00:19.920]  So usually what I'll do if I have like a certain idea or a simple note, like I'll pull up Neovim\n",
            "[00:19.920 --> 00:25.440]  and just go like ideas and then I just pull up my ideas and kind of toss them into here.\n",
            "[00:25.440 --> 00:29.120]  And then if I like want to expand on those ideas into like a tutorial or something like\n",
            "[00:29.120 --> 00:37.360]  that, usually what I'll do is create like a whole new file for that. So let's just say I'm here,\n",
            "[00:38.080 --> 00:53.600]  I'll go Hugo new, post 2023 edge removal in 2023 markdown. So usually I'll add this in and then like\n",
            "[00:53.680 --> 01:00.720]  just add it. And then I kind of go through and then notate it down. So I'm using it as a note,\n",
            "[01:00.720 --> 01:06.400]  but I'm also using it as creating a webpage as this is Hugo, a static site generator. So I've\n",
            "[01:06.400 --> 01:13.360]  kind of wired my whole workflow around an ideas page. So I can just kind of, because I don't care\n",
            "[01:13.360 --> 01:20.160]  if someone steals my ideas, have at them. Like I said, it's I do this stuff more for so people to\n",
            "[01:20.240 --> 01:28.560]  learn. And then the aspect of actually like formulating a whole like tutorial or something\n",
            "[01:28.560 --> 01:33.440]  like that where you need an expansive note, I treat that as like creating a webpage on\n",
            "[01:33.440 --> 01:40.400]  chris tideus.com. So then I toss all this in here, I jam out whatever it as I need. And then at the\n",
            "[01:40.400 --> 01:47.200]  end, usually I'm going to create a YouTube video to go along with that expanded note slash webpage.\n",
            "[01:47.200 --> 01:52.960]  And then I just toss in the YouTube video that go along with it. And then it all gets added to\n",
            "[01:54.240 --> 02:01.600]  gets added to to that, which is kind of nice. I really enjoy this method of doing things.\n",
            "[02:04.400 --> 02:13.760]  Having said that, we'll make sure we don't actually make that I'll come back and clear it out.\n",
            "[02:14.400 --> 02:21.040]  But them them is super, super basic. I was using obsidian for a bit. But like the mind map and\n",
            "[02:21.040 --> 02:26.160]  like doing all this markdown, I was like, this is stupid. I'm literally just using this and then\n",
            "[02:26.160 --> 02:32.240]  copy pasting it and creating a webpage. So I kind of got rid of obsidian because for my\n",
            "[02:32.240 --> 02:38.960]  intense purposes, this workflow is like crowdsourcing it, making it all public as I do it.\n",
            "[02:39.920 --> 02:46.720]  So if I made like more private notes, this wouldn't work. But I don't care. So I just do it this way.\n",
            "[02:46.720 --> 02:49.760]  So everyone can see my notes as I do them, so to speak.\n",
            "[02:52.480 --> 02:56.400]  Notions good, I use notion before obsidian, I liked obsidian better than notion.\n",
            "[02:58.080 --> 03:04.320]  Web page things, there was another tool that somebody actually had me add. Let's go when you till\n",
            "[03:05.280 --> 03:13.600]  actually, let's let's launch into admin. I recently added it actually.\n",
            "[03:14.960 --> 03:19.200]  I've been trying to look up stuff. Yeah, simple note. Does anybody use simple note?\n",
            "[03:20.400 --> 03:22.000]  This is kind of an interesting one.\n",
            "[03:24.240 --> 03:32.240]  It's completely free. And it's just a simplistic note. And I think it does have like a\n",
            "[03:34.640 --> 03:40.640]  management of some sort through like OneDrive or let's see.\n",
            "[03:43.760 --> 03:46.320]  Anyways, yeah, I was looking at this, I was like, that's kind of interesting.\n",
            "[03:47.920 --> 03:53.200]  So if you're looking for something like, I guess some people still use like Google Keep\n",
            "[03:53.200 --> 04:00.240]  or something. I did once upon a time. So no knock on that. It's just like this would be\n",
            "[04:00.240 --> 04:04.000]  probably a better solution if you want something more simplistic. And then if you want to expand\n",
            "[04:04.000 --> 04:10.320]  from that notions decent, but I'm kind of falling out of love with notion and then obsidian, I really\n",
            "[04:10.320 --> 04:14.720]  enjoyed if you're really like hardcore and advanced note taking, I think obsidians where a lot of\n",
            "[04:14.720 --> 04:18.480]  people would be, but simple note, if you just want something simple, I think would probably be a good\n",
            "[04:18.480 --> 04:24.400]  one. I saw that I'm going to add that in in a future update as well. Yeah, yeah, I don't use obsidian\n",
            "[04:24.400 --> 04:32.640]  anymore. So I kind of got rid of obsidian just because it did so much and I really didn't utilize it.\n",
            "[04:33.600 --> 04:40.080]  There's one plugin I really missed from obsidian, which was who's a fantastic,\n",
            "[04:41.120 --> 04:47.520]  I think it was like Excel draw kind of thing. Yeah, Excel a draw. Yeah, that's it. However you say it.\n",
            "[04:48.160 --> 04:54.800]  I loved that. That was so much so good. Let's see.\n",
            "[04:57.920 --> 05:00.240]  I'm just going to get rid of it. I'm not going to use it.\n",
            "Generated srt and txt file in the Google Drive -> Whisper -> result Folder\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(model_user)\n",
        "\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "filename = \"audio.mp3\"\n",
        "input_directory = \"content\"\n",
        "input_file = f\"{input_directory}/{filename}\"\n",
        "if language.lower() == '':\n",
        "  result = model.transcribe(input_file, verbose=True, task=task)\n",
        "else:\n",
        "  result = model.transcribe(input_file, verbose=True, task=task, language=language)\n",
        "\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  transcription_root = \"/content/gdrive/MyDrive/Whisper/result\"\n",
        "\n",
        "else:\n",
        "  os.mkdir(\"result\")\n",
        "  transcription_root = \"/content/result\"\n",
        "\n",
        "# Setup Options for SRT/TXT file\n",
        "options = {\n",
        "    'max_line_width': None,\n",
        "    'max_line_count': None,\n",
        "    'highlight_words': False\n",
        "}\n",
        "\n",
        "# Save as an SRT file\n",
        "srt_writer = get_writer(\"srt\", transcription_root,)\n",
        "srt_writer(result, new_filename, options)\n",
        "\n",
        "if Generate_Plain_Document.lower() == \"yes\":\n",
        "\n",
        "  # Save as TXT file\n",
        "  srt_writer = get_writer(\"txt\", transcription_root,)\n",
        "  srt_writer(result, new_filename2, options)\n",
        "  print(\"Generated srt and txt file in the Google Drive -> Whisper -> result Folder\")\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Generated srt file in the Google Drive -> Whisper -> result Folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Google Drive Gets Disabled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7rWCkivc2Jhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os.path\n",
        "import requests\n",
        "from google.colab import files\n",
        "from transfersh_client.app import send_to_transfersh, create_zip, remove_file\n",
        "\n",
        "if disable_google_drive.lower() == 'yes':\n",
        "    # Creating the ZIP file\n",
        "    archived = shutil.make_archive(new_filename, 'zip', '/content/result')\n",
        "\n",
        "    if os.path.exists(archived):\n",
        "        print(archived)\n",
        "\n",
        "        if shutdown_after_complete.lower() == \"yes\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        elif download_method.lower() == \"anonfile\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        elif download_method.lower() == \"transfer.sh\":\n",
        "            # Upload to transfer.sh\n",
        "            def send_files_from_dir():\n",
        "              directory = '/content'\n",
        "              send_to_transfersh(archived, clipboard=False)  # sends archive to transfer.sh\n",
        "\n",
        "\n",
        "            if __name__ == '__main__':\n",
        "              send_files_from_dir()\n",
        "\n",
        "        else:\n",
        "            files.download(archived)\n",
        "            print(\"File downloaded successfully.\")\n",
        "\n",
        "    else:\n",
        "        print(\"ZIP file not created\")"
      ],
      "metadata": {
        "id": "H-PkcMx22JTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccbf184-cc69-428a-c6c2-1e2a1c195248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/How I Take Notes in 2023.srt.zip\n",
            "\n",
            "Sending file: How I Take Notes in 2023.srt.zip (size of the file: 0.004128 MB)\n",
            "Link to download file(will be saved till 2023-08-16):\n",
            "https://transfer.sh/uVxUrhzLYr/How%20I%20Take%20Notes%20in%202023.srt.zip\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM61x2JuYBl-"
      },
      "source": [
        "# Auto Shutdown the Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUKHF0-rYGvq"
      },
      "outputs": [],
      "source": [
        "if shutdown_after_complete.lower() == \"yes\":\n",
        "    print(\"Shutting Down the Runtime Because Shutdown After Complete is on\")\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HiME-JOSUfhd"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOy448LPBpnWOFf5ps59Q+X",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}