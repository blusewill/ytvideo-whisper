{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blusewill/ytvideo-whisper/blob/dev/ytvideo_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQL1GjFTNNp"
      },
      "source": [
        "# ytvideo-whisper\n",
        "\n",
        "This Project uses the Original [Whisper](https://github.com/openai/whisper) Project instead of Decipher Project.\n",
        "\n",
        "For Everyone who want to use the Original Whisper Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZvIN-oUKdx"
      },
      "source": [
        "# Usage\n",
        "\n",
        "1. Check the Runtime Type is on GPU Mode in ``Runtime -> Change Runtime Type ``\n",
        "1. Change the Settings at Settings Code Block\n",
        "1. Click ``Runtime -> Run all`` (CTRL+F9)\n",
        "1. Click on the Connect to Google Drive\n",
        "1. And Wait for a moment your Generated Srt should be on ``Google Drive -> Whisper -> result``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpjyRvaUVZh"
      },
      "source": [
        "## Add Google Drive Access \n",
        "(at Google Drive/Whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M2C9UlxTCjE"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Download Opition**\n",
        "disable_google_drive = \"no\" #@param ['yes', 'no']\n",
        "download_method = \"anonfile\" #@param ['anonfile', 'direct']\n",
        "#@markdown The Driect Method will **NOT** Working if the ``shutdown_after_complete`` is enabled. It will **Fall Back to anonfile** instead.\n",
        "#@markdown # Disclaimer : The Direct Download sometimes doesn't work on Firefox Type Web Browser. </p> Please **use anonfile instead**\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  path = '/content/gdrive/MyDrive/Whisper/'\n",
        "  path2 = '/content/gdrive/MyDrive/Whisper/result'\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiME-JOSUfhd"
      },
      "source": [
        "# Install Components\n",
        "\n",
        "Package : yt-dlp ffmpeg openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXCqLjY0Uz0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63067e5-5f20-4ca4-b631-5f21dd8aef08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20230314.tar.gz (792 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.9/792.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.3.4-py2.py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Collecting tiktoken==0.3.1 (from openai-whisper)\n",
            "  Downloading tiktoken-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.5)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2022.12.7)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, ffmpeg\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796910 sha256=d0f2ea017b7dc3fd898d113261a05fed6a4ec906ab28817fbcf1a2573b90d34f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/13/5f/fe8245f6dc59df505879da4b2129932e342f02a80e6b87f27d\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=a767fbdf31ad11916966eb7501b6d352413e167d79a9db8dc7e7046e29f7f33d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built openai-whisper ffmpeg\n",
            "Installing collected packages: ffmpeg, brotli, websockets, pycryptodomex, mutagen, jedi, ffmpeg-python, yt-dlp, tiktoken, openai-whisper\n",
            "Successfully installed brotli-1.0.9 ffmpeg-1.4 ffmpeg-python-0.2.0 jedi-0.18.2 mutagen-1.46.0 openai-whisper-20230314 pycryptodomex-3.18.0 tiktoken-0.3.1 websockets-11.0.3 yt-dlp-2023.3.4\n"
          ]
        }
      ],
      "source": [
        "! pip install openai-whisper yt-dlp ffmpeg ipython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfd0B3nU_5o"
      },
      "source": [
        "# GPU Checkup\n",
        "\n",
        "If Nothing shows up means you didn't enable GPU in the ``Runtime -> Change Runtime type``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukF_tYc9VfGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b11b30-8753-45e5-b0f3-a27ba352bf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 10 15:09:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpdHsXmVqsv"
      },
      "source": [
        "# Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IccTHdDOVxgL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#@markdown # **Video Link Here**\n",
        "# YouTube Link\n",
        "YouTube_Video_Link = \"https://www.youtube.com/watch?v=CAiUE9ZXNNU\" #@param {type:\"string\"}\n",
        "# File Name Change\n",
        "new_filename = \" The Problem with YouTube and Brodie \" #@param {type:\"string\"}\n",
        "#@markdown Note: Leave it Blank to let it audio Detect the Language\n",
        "language = \"\" #@param {type:\"string\"}\n",
        "task = \"transcribe\" #@param ['transcribe', 'translate']\n",
        "# Change it to srt file type\n",
        "new_filename = os.path.splitext(new_filename)[0] + \".srt\"\n",
        "new_filename2 = os.path.splitext(new_filename)[0] + \" Transcript.txt\"\n",
        "# Change the Model of the Whisper\n",
        "#@markdown # **Other Options**\n",
        "Generate_Plain_Document = \"yes\" #@param ['yes','no']\n",
        "shutdown_after_complete = \"yes\" #@param ['yes','no']\n",
        "model_user = \"medium\" #@param ['tiny.en','tiny','base.en','base','small.en','small','medium.en','medium','large-v1','large-v2','large']\n",
        "enable_cookies = \"no\" #@param ['yes', 'no']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Enable Cookies is Enabled\n",
        "Upload your Cookies file in here"
      ],
      "metadata": {
        "id": "MQa-cRGkAopn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "  print(\"It is not recommended to upload your main account's cookies files here, as this is a shared environment.\")\n",
        "  print(\"Your cookies might get leaked, and I will not take any responsibility if your account gets stolen.\")\n",
        "  print(\"The recommended approach is to use another Google Account's cookies to run this tool.\")\n",
        "  print(\"If it is a private video, you can share the video with that Google Account to grant access to it.\")\n",
        "  print(\"\")\n",
        "\n",
        "  from google.colab import files\n",
        "  cookies = files.upload()\n",
        "\n",
        "  # Specify the path where the files are located\n",
        "  path_cookies = \"/content\"\n",
        "\n",
        "  def rename_files(path_cookies):\n",
        "      for filename in os.listdir(path_cookies):\n",
        "          file_path = os.path.join(path_cookies, filename)\n",
        "          if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
        "              new_path = os.path.join(path_cookies, \"cookies.txt\")\n",
        "              os.rename(file_path, new_path)\n",
        "\n",
        "  rename_files(path_cookies)"
      ],
      "metadata": {
        "id": "hPMZ1BQLAoY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vEu7rbV6xJ"
      },
      "source": [
        "# Download the Video\n",
        "using the yt-dlp and ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6o0YbciV_aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de976605-8a3a-44fb-fc33-124c116137de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=CAiUE9ZXNNU\n",
            "[youtube] CAiUE9ZXNNU: Downloading webpage\n",
            "[youtube] CAiUE9ZXNNU: Downloading android player API JSON\n",
            "[info] CAiUE9ZXNNU: Downloading 1 format(s): 251\n",
            "[dashsegments] Total fragments: 1\n",
            "[download] Destination: content/audio\n",
            "[download] 100% of    3.14MiB in 00:00:00 at 16.46MiB/s              \n",
            "[ExtractAudio] Destination: content/audio.mp3\n",
            "Deleting original file content/audio (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "import yt_dlp\n",
        "\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "\n",
        "  ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "          'cookiefile': 'cookies.txt'\n",
        "  }\n",
        "\n",
        "else:\n",
        "\n",
        "    ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'mp3',\n",
        "          'preferredquality': '192',\n",
        "      }],\n",
        "          'outtmpl': 'content/audio',\n",
        "  }\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([YouTube_Video_Link])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzO86nhoWPu2"
      },
      "source": [
        "# Generating the SRT file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnFM1sy3WTBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c221c3aa-b782-4dc9-cc48-35ec3059c463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 159MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.560]  Yeah, and just pulling in your subscriptions is the biggest thing. That's what I like.\n",
            "[00:04.560 --> 00:09.280]  Because generally a lot of the people that I like watching won't show up in my feed\n",
            "[00:09.280 --> 00:15.120]  because they don't make videos that are algorithm friendly, that have the opportunity to\n",
            "[00:15.120 --> 00:20.960]  like explode. Like a good example of that would be your broadies of the world. Like\n",
            "[00:20.960 --> 00:26.320]  Brody Roberts and sometimes I say he makes a ton of videos, but a lot of his videos are just\n",
            "[00:26.400 --> 00:30.160]  so niche that no one's going to watch them. Hell, I won't even watch them a lot of times.\n",
            "[00:30.160 --> 00:34.720]  I'll just be like, oh, that's a neat idea, Brody. And then usually I'll just skim the video a\n",
            "[00:34.720 --> 00:40.560]  little bit. I'm like, okay, I get the gist of it. That's cool. And then I'll go on in the next.\n",
            "[00:40.560 --> 00:49.200]  Or there's another one called the build show. It's a local home builder here. And he builds homes\n",
            "[00:49.200 --> 00:55.520]  for a living and he goes through like how to properly insulate an attic. And you know, I watch the\n",
            "[00:55.600 --> 00:58.880]  video from him, the other day. And I was like, oh, that's so interesting. He was addicts here.\n",
            "[00:59.760 --> 01:05.360]  You know, aren't insulated. So you have this whole space that has critters that can get up there.\n",
            "[01:05.360 --> 01:10.560]  You have all this other stuff and how to properly like do it with like maybe some close sell on the\n",
            "[01:10.560 --> 01:16.080]  outside on the going up the peak instead of doing softets with like an airflow and a a vitt\n",
            "[01:16.080 --> 01:22.880]  an attic. How there's just so many better ways to build homes that we don't do today. And not very many\n",
            "[01:22.960 --> 01:27.440]  people want to watch that video. But damn it. It's so interesting to me. So there's those little\n",
            "[01:27.440 --> 01:32.320]  things in there where I like to kind of just stuff to stimulate the mind, but in a good way.\n",
            "[01:34.080 --> 01:40.400]  Yeah. Yeah. If we've probably could improve his sound. I agree with it. The thing he does, he has a\n",
            "[01:40.400 --> 01:46.960]  sure SM7B, but the gains cranked way high. So he's got this much to work with. And then he takes\n",
            "[01:47.120 --> 01:52.800]  a compressor and just, and then just jams it. I bet his ratio is sitting in like a five or six.\n",
            "[01:53.600 --> 02:02.320]  And with the excessive gain on his mic in that high compressor, it makes his voice just really\n",
            "[02:03.920 --> 02:09.600]  kind of makes you uncomfortable. It almost feels unnatural. A lot of people do that, mind you.\n",
            "[02:09.600 --> 02:16.400]  And I'm not the best audio technician trust me. But every single month I try and listen back\n",
            "[02:16.400 --> 02:21.440]  to my recordings and I'm like, how can I make this sound better? I want it to be like you sit\n",
            "[02:21.440 --> 02:28.240]  down and just like, yeah, I like the way that voice sounds. Just rolls and it just tickles the\n",
            "[02:28.240 --> 02:42.800]  ear drums. Yeah. Yeah. Yeah. Yeah. Yeah. Very very lucky. And God, Michael, Michael Hathaway\n",
            "[02:42.880 --> 02:47.840]  shout out to him. He's not in Jack today, but yeah, that's the audio engineer that helped me.\n",
            "[02:47.840 --> 02:52.720]  And he kept going, how you bought the wrong thing, man? You should have bought what I told you to\n",
            "[02:52.720 --> 02:57.840]  buy. I'm like, all right, all right. Let me buy that. And it's really great. There's still so much\n",
            "[02:57.840 --> 03:03.040]  more I can do with the audio. There's some stuff that he's like, you should buy this and like,\n",
            "[03:03.040 --> 03:08.960]  that's a little bit too much money for me. But I do know in the future, if I want to improve my\n",
            "[03:09.040 --> 03:16.640]  audio more, I need to step it up and move to that. And it just helps so much. Yeah. And I\n",
            "[03:16.640 --> 03:22.400]  appreciate the harassment because it's nice. So I think Brody eventually get there. There's just so\n",
            "[03:22.400 --> 03:28.000]  much that goes into creating stuff that people don't think about when it comes to the way it sounds,\n",
            "[03:28.000 --> 03:32.960]  the way it looks, all those things. And I, I'm no expert. I just, I know enough.\n",
            "Generated srt and txt file in the Google Drive -> Whisper -> result Folder\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(model_user)\n",
        "\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "filename = \"audio.mp3\"\n",
        "input_directory = \"content\"\n",
        "input_file = f\"{input_directory}/{filename}\"\n",
        "if language.lower() == '':\n",
        "  result = model.transcribe(input_file, verbose=True, task=task)\n",
        "else:\n",
        "  result = model.transcribe(input_file, verbose=True, task=task, language=language)\n",
        "\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  transcription_root = \"/content/gdrive/MyDrive/Whisper/result\"\n",
        "\n",
        "else:\n",
        "  os.mkdir(\"result\")\n",
        "  transcription_root = \"/content/result\"\n",
        "\n",
        "# Save as an SRT file\n",
        "srt_writer = get_writer(\"srt\", transcription_root,)\n",
        "srt_writer(result, new_filename)\n",
        "\n",
        "if Generate_Plain_Document.lower() == \"yes\":\n",
        "\n",
        "  # Save as TXT file\n",
        "  srt_writer = get_writer(\"txt\", transcription_root,)\n",
        "  srt_writer(result, new_filename2)\n",
        "  print(\"Generated srt and txt file in the Google Drive -> Whisper -> result Folder\")\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Generated srt file in the Google Drive -> Whisper -> result Folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Google Drive Gets Disabled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7rWCkivc2Jhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os.path\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "if disable_google_drive.lower() == 'yes':\n",
        "    # Creating the ZIP file\n",
        "    archived = shutil.make_archive(new_filename, 'zip', '/content/result')\n",
        "\n",
        "    if os.path.exists(archived):\n",
        "        print(archived)\n",
        "\n",
        "        if shutdown_after_complete.lower() == \"yes\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        elif download_method.lower() == \"anonfile\":\n",
        "            # Upload the file to Anonfiles\n",
        "            upload_url = \"https://api.anonfiles.com/upload\"\n",
        "            with open(archived, 'rb') as file:\n",
        "                response = requests.post(upload_url, files={'file': file})\n",
        "\n",
        "            # Check if the upload was successful\n",
        "            if response.status_code == 200 and response.json()['status']:\n",
        "                download_url = response.json()['data']['file']['url']['full']\n",
        "                print(f\"File uploaded successfully to Anonfiles. Download link: {download_url}\")\n",
        "            else:\n",
        "                print(\"File upload to Anonfiles failed.\")\n",
        "\n",
        "        else:\n",
        "            files.download(archived)\n",
        "            print(\"File downloaded successfully.\")\n",
        "\n",
        "    else:\n",
        "        print(\"ZIP file not created\")"
      ],
      "metadata": {
        "id": "H-PkcMx22JTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2b5804-efd8-4248-de56-2463537f09ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ The Problem with YouTube and Brodie .srt.zip\n",
            "File uploaded successfully to Anonfiles. Download link: https://anonfiles.com/l38bdbw5z5/_The_Problem_with_YouTube_and_Brodie_srt_zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM61x2JuYBl-"
      },
      "source": [
        "# Auto Shutdown the Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUKHF0-rYGvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26990e2a-c573-45ad-f078-03ebdc4f5160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shutting Down the Runtime Because Shutdown After Complete is on\n"
          ]
        }
      ],
      "source": [
        "if shutdown_after_complete.lower() == \"yes\":\n",
        "    print(\"Shutting Down the Runtime Because Shutdown After Complete is on\")\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HiME-JOSUfhd"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyO6ZZ+RWsZ7DTJrRRti5GKq",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}