{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blusewill/ytvideo-whisper/blob/dev/ytvideo_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQL1GjFTNNp"
      },
      "source": [
        "# ytvideo-whisper\n",
        "\n",
        "This Project uses the Original [Whisper](https://github.com/openai/whisper) Project instead of Decipher Project.\n",
        "\n",
        "For Everyone who want to use the Original Whisper Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZvIN-oUKdx"
      },
      "source": [
        "# Usage\n",
        "\n",
        "1. Check the Runtime Type is on GPU Mode in ``Runtime -> Change Runtime Type ``\n",
        "1. Change the Settings at Settings Code Block\n",
        "1. Click ``Runtime -> Run all`` (CTRL+F9)\n",
        "1. Click on the Connect to Google Drive\n",
        "1. And Wait for a moment your Generated Srt should be on ``Google Drive -> Whisper -> result``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTpjyRvaUVZh"
      },
      "source": [
        "## Add Google Drive Access\n",
        "(at Google Drive/Whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-M2C9UlxTCjE"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Download Opition**\n",
        "disable_google_drive = \"no\" #@param ['yes', 'no']\n",
        "download_method = \"bashupload\" #@param ['bashupload', 'direct']\n",
        "#@markdown The Driect Method will **NOT** Working if the ``shutdown_after_complete`` is enabled. It will **Fall Back to bashupload** instead.\n",
        "#@markdown # Disclaimer : The Direct Download sometimes doesn't work on Firefox Type Web Browser. </p> Please **use anonfile or transfer.sh instead**\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  path = '/content/gdrive/MyDrive/Whisper/'\n",
        "  path2 = '/content/gdrive/MyDrive/Whisper/result'\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  if not os.path.exists(path):\n",
        "    os.mkdir(path)\n",
        "    os.mkdir(path2)\n",
        "\n",
        "# Calcuate the Execution Time.\n",
        "from datetime import datetime\n",
        "start_time = datetime.now()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiME-JOSUfhd"
      },
      "source": [
        "# Install Components\n",
        "\n",
        "Package : openai-whisper yt-dlp ipython pyperclip wget pycurl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aXCqLjY0Uz0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b17e25-9e88-4fc5-bde5-716f9a7811c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.5.26-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: pyperclip in /usr/local/lib/python3.10/dist-packages (1.8.2)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycurl\n",
            "  Downloading pycurl-7.45.3-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.2.2)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.14.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, wget\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=6996b12fc82f2f3e439c455115e87bad15564fd502a170e08bb211ef681a54b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=acb3a5b82f5d69843f2f58d619a70d96a553f3b05fe52d8db1b97b5dae2db246\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built openai-whisper wget\n",
            "Installing collected packages: wget, brotli, websockets, pycurl, pycryptodomex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mutagen, jedi, yt-dlp, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed brotli-1.1.0 jedi-0.19.1 mutagen-1.47.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 pycryptodomex-3.20.0 pycurl-7.45.3 tiktoken-0.7.0 websockets-12.0 wget-3.2 yt-dlp-2024.5.26\n"
          ]
        }
      ],
      "source": [
        "! apt-get install ffmpeg\n",
        "! pip install openai-whisper yt-dlp ipython pyperclip wget pycurl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWfd0B3nU_5o"
      },
      "source": [
        "# GPU Checkup\n",
        "\n",
        "If Nothing shows up means you didn't enable GPU in the ``Runtime -> Change Runtime type``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ukF_tYc9VfGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f357858-d9ad-4ad6-a5c1-1bf2c7f3c28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 27 17:16:31 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpdHsXmVqsv"
      },
      "source": [
        "# Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IccTHdDOVxgL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#@markdown File Format **must be mp3**\n",
        "upload_own_audio_file = \"no\" #@param ['yes', 'no']\n",
        "#@markdown # **Video Link Here**\n",
        "# YouTube Link\n",
        "YouTube_Video_Link = \"https://www.youtube.com/watch?v=VleFAF1Qav0\" #@param {type:\"string\"}\n",
        "# File Name Change\n",
        "new_filename = \"Discord is getting a New Look!\" #@param {type:\"string\"}\n",
        "#@markdown Note: Leave it Blank to let it audio Detect the Language\n",
        "language = \"\" #@param {type:\"string\"}\n",
        "task = \"transcribe\" #@param ['transcribe', 'translate']\n",
        "# Change it to srt file type\n",
        "new_filename = os.path.splitext(new_filename)[0] + \".srt\"\n",
        "new_filename2 = os.path.splitext(new_filename)[0] + \" Transcript.txt\"\n",
        "# Change the Model of the Whisper\n",
        "#@markdown # **Other Options**\n",
        "Generate_Plain_Document = \"yes\" #@param ['yes','no']\n",
        "shutdown_after_complete = \"yes\" #@param ['yes','no']\n",
        "model_user = \"medium\" #@param ['tiny.en','tiny','base.en','base','small.en','small','medium.en','medium','large-v1','large-v2','large']\n",
        "enable_cookies = \"no\" #@param ['yes', 'no']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Enable Cookies is Enabled\n",
        "Upload your Cookies file in here"
      ],
      "metadata": {
        "id": "MQa-cRGkAopn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if enable_cookies.lower() == \"yes\":\n",
        "  print(\"It is not recommended to upload your main account's cookies files here, as this is a shared environment.\")\n",
        "  print(\"Your cookies might get leaked, and I will not take any responsibility if your account gets stolen.\")\n",
        "  print(\"The recommended approach is to use another Google Account's cookies to run this tool.\")\n",
        "  print(\"If it is a private video, you can share the video with that Google Account to grant access to it.\")\n",
        "  print(\"\")\n",
        "\n",
        "  from google.colab import files\n",
        "  cookies = files.upload()\n",
        "\n",
        "  # Specify the path where the files are located\n",
        "  path_cookies = \"/content\"\n",
        "\n",
        "  def rename_files(path_cookies):\n",
        "      for filename in os.listdir(path_cookies):\n",
        "          file_path = os.path.join(path_cookies, filename)\n",
        "          if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
        "              new_path = os.path.join(path_cookies, \"cookies.txt\")\n",
        "              os.rename(file_path, new_path)\n",
        "\n",
        "  rename_files(path_cookies)"
      ],
      "metadata": {
        "id": "hPMZ1BQLAoY9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1vEu7rbV6xJ"
      },
      "source": [
        "# Download the Video or upload the audio\n",
        "using the yt-dlp and ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o6o0YbciV_aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b509c198-fd1b-4cab-9bd8-8c34370c70b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=VleFAF1Qav0\n",
            "[youtube] VleFAF1Qav0: Downloading webpage\n",
            "[youtube] VleFAF1Qav0: Downloading ios player API JSON\n",
            "[youtube] VleFAF1Qav0: Downloading player bc657243\n",
            "[youtube] VleFAF1Qav0: Downloading m3u8 information\n",
            "[info] VleFAF1Qav0: Downloading 1 format(s): 251\n",
            "[download] Destination: content/audio\n",
            "[download] 100% of    8.28MiB in 00:00:00 at 59.87MiB/s  \n",
            "[ExtractAudio] Destination: content/audio.mp3\n",
            "Deleting original file content/audio (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "import yt_dlp\n",
        "\n",
        "if upload_own_audio_file == \"yes\":\n",
        "  if not os.path.isfile('audio.mp3'):\n",
        "      own_audio = files.upload()\n",
        "      if not os.path.exists('content'):\n",
        "        os.mkdir('content')\n",
        "        for filename in own_audio.keys():\n",
        "            os.rename(filename, 'audio.mp3')\n",
        "            os.replace('audio.mp3', 'content/audio.mp3')\n",
        "\n",
        "else:\n",
        "    if enable_cookies.lower() == \"yes\":\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'content/audio',\n",
        "            'cookiefile': 'cookies.txt'\n",
        "        }\n",
        "    else:\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': 'content/audio',\n",
        "        }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([YouTube_Video_Link])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzO86nhoWPu2"
      },
      "source": [
        "# Generating the SRT file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZnFM1sy3WTBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315c8df8-5af8-4e57-f1c6-fc8508e853d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:16<00:00, 93.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded.\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.960]  Discord is getting a whole new look with new themes and new app icons, but there are also some interesting\n",
            "[00:05.340 --> 00:11.120]  experimental features which some people have right now that change how discord looks and feels but first let's take a look at\n",
            "[00:11.120 --> 00:15.860]  Discord's refresh which comes out sometime in the future. I don't have an ETA\n",
            "[00:15.860 --> 00:16.360]  I'm sorry\n",
            "[00:16.360 --> 00:19.480]  Now if you're not some sort of loser like myself that gives discord money\n",
            "[00:19.480 --> 00:21.480]  You can make discord look one of two ways\n",
            "[00:22.000 --> 00:28.660]  Flashbang white or just normal gray and if you do buy discord you have all of these themes which I've never used because I just\n",
            "[00:28.820 --> 00:34.080]  The original discord but ladies and gentlemen, it's 2024 which means absolutely nothing\n",
            "[00:34.080 --> 00:38.040]  But discord now has four themes that you can choose from for free\n",
            "[00:38.120 --> 00:41.500]  Unless discord changes something between the time of recording this and when it comes out\n",
            "[00:41.500 --> 00:47.700]  But I digress but instead of having flashbang white and normal gray you now have darker which I don't know looks are subjective\n",
            "[00:47.700 --> 00:51.120]  You could like this you could hate it. I'm more of a fan of the midnight color\n",
            "[00:51.120 --> 00:54.760]  I can use discord late at night as if I didn't already do that already\n",
            "[00:54.760 --> 00:57.780]  But now it'll be a lot more comfortable now to be honest\n",
            "[00:57.780 --> 01:01.780]  Like it's kind of hard to tell how big of a difference this is until you go back to the normal theme\n",
            "[01:01.780 --> 01:04.240]  And I mean these themes were already on mobile\n",
            "[01:04.240 --> 01:05.940]  They had midnight before as an Easter egg\n",
            "[01:05.940 --> 01:12.000]  But after five years three months and 25 days discord has decided to yes put these themes on the stinking desktop\n",
            "[01:12.000 --> 01:16.420]  But if you give discord money, you're not just stuck with darker and midnight\n",
            "[01:16.420 --> 01:19.960]  In fact, I'm gonna need a drum roll whatever stock sound effect\n",
            "[01:19.960 --> 01:23.040]  I use is probably the most garbage drum roll on the planet\n",
            "[01:23.060 --> 01:26.540]  But we have a new theme called blurple Twilight\n",
            "[01:26.540 --> 01:33.340]  Which looks worse than the free themes that we get and there's a blurple Twilight feature looks exactly like midnight blurple\n",
            "[01:33.340 --> 01:37.460]  I'm switching between them and like there's a very little difference very little difference\n",
            "[01:37.460 --> 01:42.980]  And if you're slightly colorblind, there's no difference at all. It looks basically the same. Oh, but gee good golly\n",
            "[01:42.980 --> 01:44.820]  That's not all with this new refresh\n",
            "[01:44.820 --> 01:48.700]  In fact, it goes all downhill from here with this new discord app refresh\n",
            "[01:48.720 --> 01:53.160]  You have I know a whole new app icon if I had socks on right now\n",
            "[01:53.160 --> 01:56.760]  They'd be knocked clean off to expose my beautiful toes with foot fungus\n",
            "[01:56.760 --> 01:59.160]  I don't know how to take care of myself and with this refresh\n",
            "[01:59.160 --> 02:04.120]  There's also a new background when you log in on the mobile app. Like I told you things were going downhill\n",
            "[02:04.880 --> 02:06.120]  Actually, I just lied to you\n",
            "[02:06.120 --> 02:11.440]  It turns out discord did a little bit of a sneaky update and this background will be available on the desktop and we have photos\n",
            "[02:11.440 --> 02:13.440]  Of it and to be honest, it looks really nice\n",
            "[02:13.440 --> 02:19.580]  But another thing that discord is working on that might not have a unanimous praise is the fact that they're making new Pride Day\n",
            "[02:19.580 --> 02:24.100]  App icons and like I said people are gonna be upset about this for one of two reasons one\n",
            "[02:24.300 --> 02:30.060]  Apparently rainbows hurt people's feelings or something or the second reason is that these icons are nitro only?\n",
            "[02:30.100 --> 02:33.420]  So you need to pay discord to be gay that was discords refresh\n",
            "[02:33.420 --> 02:39.100]  But you should really refresh your rooms decor with this video sponsor disc plate. So I never go outside\n",
            "[02:39.120 --> 02:42.720]  I'm in my room all day long, which has nothing on the walls\n",
            "[02:42.720 --> 02:47.600]  It's devoid of character because my landlord would hire a hitman if I hammered something into the walls\n",
            "[02:47.600 --> 02:51.120]  And I'm scared that if by some modern-day miracle I bring someone home\n",
            "[02:51.120 --> 02:55.520]  They're gonna think I'm a serial killer and call the cops and that's where disc plate comes in\n",
            "[02:55.600 --> 02:58.320]  Displates are metal posters that you hang up using magnets\n",
            "[02:58.320 --> 03:01.560]  You just slap the included protective leaf sticker onto a clean wall\n",
            "[03:01.560 --> 03:06.760]  You stick the magnet on and put on your shiny new display now displays come in different finishes\n",
            "[03:06.780 --> 03:11.020]  You have matte which looks really good for monochrome display to you have gloss to make colors pop\n",
            "[03:11.060 --> 03:17.780]  But like Hannah Montana said you can get the best of both worlds with this plates new texture finish you get matte you get gloss\n",
            "[03:17.780 --> 03:20.940]  And you get this 3d texture to make your disc plate stand out\n",
            "[03:20.940 --> 03:22.700]  No, if you don't like my cat display\n",
            "[03:22.700 --> 03:24.500]  I am deeply offended but\n",
            "[03:24.500 --> 03:30.840]  Displate has over 2 million designs on their website and you're bound to find something you like from officially licensed designs like Star Wars and\n",
            "[03:30.840 --> 03:38.080]  And ring to independent artists with some hidden gems all quickly delivered to your basement dungeon from the EU in fortified business days\n",
            "[03:38.080 --> 03:43.980]  Check out display by using my link display comm slash no text or use code no text for up to\n",
            "[03:44.300 --> 03:48.900]  42% off your order and I think now it's time to go back to discourse\n",
            "[03:49.380 --> 03:54.520]  Experimental features and the first experimental feature I'm gonna talk about is simplified profile experiment\n",
            "[03:54.520 --> 03:59.500]  So, you know when you click on someone's profile and there's so much stuff that it blasts you away and it's hard for your skimity\n",
            "[03:59.500 --> 04:05.900]  Toilet swiss cheese brain to comprehend. Oh, that's just me. I guess well, that's what this experiment is trying to solve now originally profiles\n",
            "[04:05.900 --> 04:11.500]  Look like this, but if you enable the experiment profiles look actually really good. It's minimal. It's clean\n",
            "[04:11.500 --> 04:14.280]  You're not being blasted away by 500 pieces of information\n",
            "[04:14.500 --> 04:21.540]  But of course, of course when I'm happy other people aren't happy and people complained about this like no tomorrow because change is always bad\n",
            "[04:21.540 --> 04:23.140]  Life was peaceful and good\n",
            "[04:23.140 --> 04:28.840]  But the second we invented taxes everything went downhill and that's why with this experiment there are multiple options\n",
            "[04:28.840 --> 04:35.860]  You have only the basics and then you have more user details and since people are complaining about this super minimal look which looks good\n",
            "[04:35.860 --> 04:38.600]  In my opinion instead when we go through people's profiles\n",
            "[04:38.600 --> 04:44.420]  I'm gonna be using the more user details experiment just so we get a good idea on how this will look when it comes out\n",
            "[04:44.420 --> 04:49.960]  So when you click on someone's profile, it is no longer something that is longer than my bath and body works receipt\n",
            "[04:49.960 --> 04:52.640]  It's now condensed and actually fits on the screen\n",
            "[04:52.960 --> 04:56.480]  Longer is not always better and you can see with this new profile feature\n",
            "[04:56.480 --> 05:00.740]  A lot of things are moved around for statuses. It's not just something that's thrown on your profile\n",
            "[05:00.740 --> 05:05.200]  It's this little thought bubble that kind of reminds me of Skype. Oh my age is showing but as we move down\n",
            "[05:05.200 --> 05:12.120]  There are three really big changes that I like and the first big change is that that big notes thing that appears on someone's profile\n",
            "[05:12.120 --> 05:13.800]  At the bottom that's gone now\n",
            "[05:13.800 --> 05:18.640]  It's just this little icon where you can hover over it and see someone's notes and you can click on it and edit their notes\n",
            "[05:18.640 --> 05:25.600]  Just like normal you have your good old display name username pronouns and our discord badges have moved from the top right down to the bottom\n",
            "[05:25.600 --> 05:28.360]  And why did discord do this? I literally just thought of this\n",
            "[05:28.360 --> 05:34.560]  I feel like a genius but there are people that change their discord banners to have badges in them and that's been used for scamming\n",
            "[05:34.560 --> 05:41.080]  So I think discord moving it away from the top right in the banner and down into someone's profile will probably help people from\n",
            "[05:41.080 --> 05:42.960]  Not being scammed now in their profile\n",
            "[05:42.960 --> 05:46.760]  You can easily see how many mutual friends and mutual servers you have just from a glance\n",
            "[05:46.760 --> 05:52.560]  But the second biggest feature is that you don't have to see everyone's whole bio when you click on their profile instead\n",
            "[05:52.600 --> 05:57.480]  It gets cropped off and you can click on view full bio. Honestly, it seems really small\n",
            "[05:57.480 --> 06:03.640]  But this turns your big laundry list profile into something that's a lot shorter now activities look a little bit different\n",
            "[06:03.640 --> 06:05.920]  Which in my opinion look a lot better and more modern\n",
            "[06:05.920 --> 06:10.980]  But the third and final big feature is that you don't see everyone's roles on their profile\n",
            "[06:10.980 --> 06:13.640]  You know if you go on those e-girl hangout discord servers\n",
            "[06:13.640 --> 06:18.640]  Which by the way worst mistake of my life if you click on someone's profile, they have 500 roles\n",
            "[06:18.720 --> 06:20.480]  Why because you got to feel special\n",
            "[06:20.520 --> 06:25.440]  I think discords realizing that people should grow up and now what they've done is they made it where if people have a\n",
            "[06:25.440 --> 06:31.000]  Whole bunch of roles it gets shoved into this overflow menu where you can click on it and it takes you to the full profile\n",
            "[06:31.000 --> 06:34.040]  Where you can see everyone's roles, but this is the whole discord profile\n",
            "[06:34.040 --> 06:36.000]  You can see that a lot of design elements remain\n",
            "[06:36.000 --> 06:41.480]  But the main thing is that all this crap didn't show up in the profile. I don't mean that in a mean way\n",
            "[06:41.480 --> 06:45.960]  I just mean that in terms of I've already read it and I have a memory that lasts longer than five seconds\n",
            "[06:45.960 --> 06:52.040]  What was I saying again now when you aren't frequently stalking your friends profiles and disguising it as a YouTube video to show off a\n",
            "[06:52.040 --> 06:55.360]  Discord experiment, what are you doing instead? You're hitting the discord gym\n",
            "[06:55.360 --> 07:01.240]  You're doing a hundred hardcore reps of checking your discord servers to see if people are online and ready to talk to you\n",
            "[07:01.240 --> 07:03.280]  And if that's you and not just me well\n",
            "[07:03.280 --> 07:08.680]  You're in luck because discord has the experiment change the guilds tool tip whatever that means\n",
            "[07:08.680 --> 07:11.200]  But if you enable this bad boy, you have a couple options\n",
            "[07:11.200 --> 07:12.680]  I don't know what either of them do\n",
            "[07:12.680 --> 07:17.840]  But when you enable it and you go back to your discord when you hover over a profile says no one's in the voice chat yet\n",
            "[07:17.840 --> 07:21.440]  voice channels are for hanging out when you're ready to talk just hop in just\n",
            "[07:21.600 --> 07:25.080]  Encourage you and your friends to actually hang out with you and with this pop-up\n",
            "[07:25.080 --> 07:27.280]  You can actually directly join a voice channel\n",
            "[07:27.280 --> 07:31.720]  But if you're in a discord server that is bumping you can see that there are a couple things that pop up first\n",
            "[07:31.720 --> 07:36.560]  You can see people in a voice call and you can join it directly and see what games are playing and you can also see\n",
            "[07:36.640 --> 07:40.800]  Events and if you're doing a little bit of discord mod duties and viewing the server as a role\n",
            "[07:40.800 --> 07:44.320]  It'll also tell you in the pop-up and if you're on a discord server that has invites paused\n",
            "[07:44.320 --> 07:48.560]  It will also show up in this menu now. I'm gonna be honest with this experiment\n",
            "[07:48.560 --> 07:51.700]  It does the exact opposite of what the simplified profiles\n",
            "[07:52.080 --> 08:00.240]  experimented profiles were long with a whole bunch of information and they got shrunk before this experiment servers looked completely normal, but now they have even more\n",
            "[08:00.560 --> 08:03.760]  Information and it's actually worse and like bigger discord servers\n",
            "[08:03.920 --> 08:10.440]  Like this is excessive man, and it turns out visual clutter is still on the menu because discord has their final experiment\n",
            "[08:10.440 --> 08:15.720]  I want to talk about discord wants to add in your members list and activity section where you can see what your friends or people\n",
            "[08:15.720 --> 08:21.400]  On the server are doing and again, it's more clutter, but things don't seem too bad because you can just you know\n",
            "[08:21.400 --> 08:27.320]  Collapse the menu so with discords visual overhaul there are gonna be some wins and there are gonna be some losses\n",
            "[08:27.480 --> 08:31.000]  Assuming discord continues with what they're showing here today. Anywho gamer\n",
            "[08:31.000 --> 08:36.240]  That's what discords been cooking up in the studio. And again, thank you display for sponsoring the video and thank you\n",
            "[08:36.240 --> 08:39.640]  Yes, you listening to my voice right now for watching. I love you. Bye. Bye\n",
            "Generated srt and txt file in the Google Drive -> Whisper -> result Folder\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(model_user)\n",
        "\n",
        "print(\"Whisper model loaded.\")\n",
        "\n",
        "\n",
        "from whisper.utils import get_writer\n",
        "\n",
        "filename = \"audio.mp3\"\n",
        "input_directory = \"content\"\n",
        "input_file = f\"{input_directory}/{filename}\"\n",
        "if language.lower() == '':\n",
        "  result = model.transcribe(input_file, verbose=True, task=task)\n",
        "else:\n",
        "  result = model.transcribe(input_file, verbose=True, task=task, language=language)\n",
        "\n",
        "if disable_google_drive.lower() == 'no':\n",
        "\n",
        "  transcription_root = \"/content/gdrive/MyDrive/Whisper/result\"\n",
        "\n",
        "else:\n",
        "  os.mkdir(\"result\")\n",
        "  transcription_root = \"/content/result\"\n",
        "\n",
        "# Setup Options for SRT/TXT file\n",
        "options = {\n",
        "    'max_line_width': None,\n",
        "    'max_line_count': None,\n",
        "    'highlight_words': False\n",
        "}\n",
        "\n",
        "# Save as an SRT file\n",
        "srt_writer = get_writer(\"srt\", transcription_root,)\n",
        "srt_writer(result, new_filename, options)\n",
        "\n",
        "if Generate_Plain_Document.lower() == \"yes\":\n",
        "\n",
        "  # Save as TXT file\n",
        "  srt_writer = get_writer(\"txt\", transcription_root,)\n",
        "  srt_writer(result, new_filename2, options)\n",
        "  print(\"Generated srt and txt file in the Google Drive -> Whisper -> result Folder\")\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"Generated srt file in the Google Drive -> Whisper -> result Folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If Google Drive Gets Disabled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7rWCkivc2Jhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os.path\n",
        "import requests\n",
        "import pycurl\n",
        "from io import BytesIO\n",
        "\n",
        "if disable_google_drive.lower() == 'yes':\n",
        "    # Creating the ZIP file\n",
        "    filenametime = datetime.now().strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
        "    archived = shutil.make_archive(filenametime, 'zip', '/content/result')\n",
        "\n",
        "    if os.path.exists(archived):\n",
        "        print(archived)\n",
        "\n",
        "        if shutdown_after_complete.lower() == \"yes\":\n",
        "          print(\"Because you can't use direct download with shutdown after complete. So we decided to switch to bashupload insead.\")\n",
        "          file_path = archived\n",
        "          upload_url = 'bashupload.com'\n",
        "          new_new_filename = f'{archived}.zip'\n",
        "\n",
        "          # Initialize a cURL object\n",
        "          c  = pycurl.Curl()\n",
        "\n",
        "          # Prepare the form data\n",
        "          c.setopt(c.URL, upload_url)\n",
        "          c.setopt(c.HTTPPOST, [\n",
        "              ('file', (\n",
        "                # Set the filename in the form data\n",
        "                  c.FORM_FILE, file_path,\n",
        "                  c.FORM_FILENAME, new_new_filename\n",
        "                )),\n",
        "            ])\n",
        "\n",
        "          # Capture the response\n",
        "          response = BytesIO()\n",
        "          c.setopt(c.WRITEFUNCTION, response.write)\n",
        "\n",
        "          # Perform the file upload\n",
        "          c.perform()\n",
        "          data = response.getvalue().decode(\"UTF-8\")\n",
        "          print(data)\n",
        "\n",
        "        elif download_method.lower() == \"bashupload\":\n",
        "          file_path = archived\n",
        "          upload_url = 'bashupload.com'\n",
        "          new_new_filename = f'{new_filename}.zip'\n",
        "\n",
        "          # Initialize a cURL object\n",
        "          c  = pycurl.Curl()\n",
        "\n",
        "          # Prepare the form data\n",
        "          c.setopt(c.URL, upload_url)\n",
        "          c.setopt(c.HTTPPOST, [\n",
        "              ('file', (\n",
        "                # Set the filename in the form data\n",
        "                  c.FORM_FILE, file_path,\n",
        "                  c.FORM_FILENAME, new_new_filename\n",
        "                )),\n",
        "            ])\n",
        "\n",
        "          # Capture the response\n",
        "          response = BytesIO()\n",
        "          c.setopt(c.WRITEFUNCTION, response.write)\n",
        "\n",
        "          # Perform the file upload\n",
        "          c.perform()\n",
        "          data = response.getvalue().decode(\"UTF-8\")\n",
        "          print(data)\n",
        "\n",
        "        else:\n",
        "            files.download(archived)\n",
        "            print(\"File downloaded successfully.\")\n",
        "\n",
        "    else:\n",
        "        print(\"ZIP file not created\")"
      ],
      "metadata": {
        "id": "H-PkcMx22JTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decae7a0-b224-4892-a699-14e53482c45f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/05-27-2024-17-24-12.zip\n",
            "Because you can't use direct download with shutdown after complete. So we decided to switch to bashupload insead.\n",
            "\n",
            "=========================\n",
            "\n",
            "Uploaded 1 file, 10 433 bytes\n",
            "\n",
            "wget http://bashupload.com/yhCjH/Zen-J.zip\n",
            "\n",
            "=========================\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM61x2JuYBl-"
      },
      "source": [
        "# Auto Shutdown the Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUKHF0-rYGvq",
        "outputId": "e319204b-34e4-41d7-c822-1b5380383927",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 0:09:31.484891\n",
            "Shutting Down the Runtime Because Shutdown After Complete is on\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "end_time = datetime.now()\n",
        "print('Execution Time: {}'.format(end_time - start_time))\n",
        "time.sleep (2)\n",
        "\n",
        "if shutdown_after_complete.lower() == \"yes\":\n",
        "    print(\"Shutting Down the Runtime Because Shutdown After Complete is on\")\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HiME-JOSUfhd"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMag2J42/ZqaLiIcqZOEHX+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}